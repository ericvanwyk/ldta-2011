\section{Objective Caml}

\cite{OcamlDef, PV, PVReuse, Exproblem, Remy, Monads, MonadicParserCombinators}

\subsection{Type-driven Transformers}

In this section we describe type-driven transformers of a certain kind which are 
massively used in our implementation. Namely, all the tasks excluding parsing
are expressed using solely the transformers of this kind. ``Type-driven'' means that
the semantics of transformers is completely determined by the transforming type; 
so all transformers can be constructed mechanically from the type definitions.
The converse is also true --- the type-driven transformer unambigiously defines
some type. We heavily utilize this property --- actually there is not a single 
type definition in our implementation: all types are introduced implicitly 
and inferred from the transformation functions. Another property of transformers
is their extensibility: each transformer operates on a data of a partially-defined, 
or \emph{open}, type. Thus transformers for the some types can be combined by a certain primitive
to provide a transformer for the union type which still remains open and so can be
combined later on. As a result we can construct a highly modular structure of
transformers each of which implements some task on a certain trait of some general
data structure. 

To implement this kind of approach a certain support from a host language type 
system is needed. Objective Caml provides such a support in particular by mean of 
\emph{polymorphic variant} types~\cite{PV}. In short, polymorphic variant types allow to 
share the same constructor between the different variant types with possibly different 
types and numbers of arguments. Polymorphic variant type need not (but can) be explicitly
declared. Another feature of polymorphic variant types is that they can be open --- in each
context only some of their constructors may be known. Polymorphic variants in Objective Caml 
can be used to express the solution for the \emph{expression problem}~\cite{Exproblem, PVReuse} --- 
that is, the problem of modular and type-safe implementation of extending data structure 
processing. 

We illustrate the construct of type-driven extensible transformers by the canonical
example --- expression evaluator. The idea is to implement evaluator as a
collection of functions each of which evaluates only the limited subset of expression's
nodes and then to combine them to construct the evaluator of the whole expression.

First, consider the function which transforms only two expression nodes ---
addition and subtraction\footnote{Polymorphic variant type constructors are lexically distinguished
from the regular ones by the backquote as their first character.}:

\begin{lstlisting}[language=ocaml]
let rec evalAddSub ext expr =
  let self = evalAddSub ext in
  match expr with
  | `Add (x, y) -> self x + self y
  | `Sub (x, y) -> self x - self y
  | z -> ext self z
\end{lstlisting}

Here \lstinline{ext} stands for the extension function --- that is, the function which
transforms the rest of polymorphic variant type's constructors besides those transformed 
by \lstinline{evalAddSub}. Note that since we want to transform potentially recursive 
structures we have to provide extension function with it's own extension function which 
should be able to transform the all nodes of expression, including \lstinline{`Add} and
\lstinline{`Sub}. This extension function (``\lstinline{self}'') is acquired by partial
application \lstinline{evalAddSub} to \lstinline{ext}.

Now we can provide two additional functions for evaluating identifiers in some state 
\lstinline{s} and multiplication:

\begin{lstlisting}[language=ocaml]
let rec evalIdent s ext expr =
  let self = evalIdent s ext in
  match expr with
  | `Ident n -> s n
  | z -> ext self z
\end{lstlisting}

\begin{lstlisting}[language=ocaml]
let rec evalMult ext expr =
  let self = evalMult ext in
  match expr with
  | `Mul (x, y) -> self x * self y
  | z -> ext self z
\end{lstlisting}

Note that the semantics of these functions is almost completely type-driven; despite
we do not have any type declaration here we actually think in terms of types, not
in terms of implementation details. The only concrete implementation-dependent feature
is the essense of constructor-specific transformation; we'll get rid of this specificity 
later. Note also that these functions are completely independent of each other; thus, they 
can be implemented in a different compilation units or provided at arbitrary moments of 
program execution.

Now we introduce the combinator which plays role of type sum:

\begin{lstlisting}[language=ocaml]
let (++) left right = fun ext s -> 
  left (fun self -> right (fun _ -> ext self)) s
\end{lstlisting}

This combinator takes extensible transformers for some open types and provides extensible transformer 
for the type of their sum. This is trivially achieved by providing appropriate extensions for each ``summands''.
For example,

\begin{lstlisting}[language=ocaml]
let evalAddSubIdent s = evalIdent s ++ evalAddSub
\end{lstlisting}

is (an extensible) function which evaluates expressions with nodes \lstinline{`Add}, \lstinline{`Sub} and
\lstinline{`Ident}. This function can further be combined:

\begin{lstlisting}[language=ocaml]
let evalAddSubIdentMult s = evalAddSubIndent s ++ evalMult
\end{lstlisting}

et cetera. 

When we need to actually apply these transformers to a data structure we have to provide
some sort of ``ultimate'' extension function; it's easy to see that this function is just
an application; in the following snippet

\begin{lstlisting}[language=ocaml]
let apply f x = f x

let x = 
  evalAddSubIdent 
     (function "a" -> 1 | "b" -> 2 | "c" -> 3 | "d" -> 4)
     apply 
     (`Add (
        `Sub (`Ident "a", 
              `Mul (`Ident "b", `Ident "c")
        ), 
        `Ident "d"
      )
     )
\end{lstlisting}

the name \lstinline{x} would be bound to \lstinline{-1}.

In the previous examples we considered some concrete transformers --- evaluators.
However a simple generalization would let us abstract this specificity away. Namely, 
we preserve the overall control flow of the transformers but parameterize the
actions carried out for each constructor. The generalized version of the first 
transformer is presented below:

\begin{lstlisting}[language=ocaml]
let rec gmapAddSub t ext expr =
  let self = gmapAddSub t ext in
  match expr with
  | `Add (x, y) -> t#add expr (self x) (self y)
  | `Sub (x, y) -> t#sub expr (self x) (self y)
  | z -> ext self z
\end{lstlisting}

Here \lstinline{t} stands for the constructor-wise transformer encoded
as an \emph{object} with methods ``\lstinline{add}'' and ``\lstinline{sub}''.
Each method takes the results of the same transformation applied to the
direct counterparts of matched value and that value itself as arguments
and returns the result of the transformation. Now the evaluation function
can be expressed as

\begin{lstlisting}[language=ocaml]
let evalAddSub ext expr = 
  gmapAddSub (object
                method add _ x y = x + y
                method sub _ x y = x - y
              end) ext expr
\end{lstlisting}

The type system of Objective Caml allows objects to be implicitly typed: there is 
no need to declare object types ``in advance''. Another feature of object
types is that they can be polymorphic. This means that the definition of
\lstinline{gmapAddSub} does not introduce any artificial type restrictions
on a set of encoded transformations. For example, the copy transformation
can be expressed using the same function but different object (of different but
``compatible'' type):

\begin{lstlisting}[language=ocaml]
let copyAddSub ext expr =
  gmapAddSb (object
               method add _ x y = `Add (x, y)
               method sub _ x y = `Sub (x, y)
             end) ext expr
\end{lstlisting}

Since each concrete transformation can be expressed as a partial application of
some generic \lstinline{gmap...} function to an object-encoded per-constructor
transformation the implementation of typ-sum combinator can be left completely 
unchanged. For example, expression evaluator for partially defined expression
of addition, subtraction and identifiers can be implemented as

\begin{lstlisting}[language=ocaml]
let evalAddSubIdent s = 
  gmapAddSub (object
                method add _ x y = x + y
                method sub _ x y = x - y
              end) ++
  gmapIdent (object method ident _ n = s n end)
\end{lstlisting}

In this approach we can easily construct transformations via combining and
extending the predefined set of object-encoded per-type transformers; in 
particular the following transformer generator was extensively used in the course
of implementation (as always we show the version for \lstinline{`Add}-\lstinline{`Sub}
type):

\begin{lstlisting}
let mapT f = object
               method add e x y = f e (`Add (x, y))
               method sub e x y = f e (`Sub (x, y))
             end
\end{lstlisting}

The final generalization consists of ``lifting'' the transformation functions
over some monad~\cite{Monads}. The implementation is straightforward so we omit it
here; we note that the parameterization over a monad is implemented using Objective 
Caml functors. In our implementation of Oberon0 we used three monads --- a variant 
of exception monad called \lstinline{Checked}, identity monad \lstinline{Id} and list 
monad \lstinline{List}. We refer to the monad-specific transformation functions for 
the two former monads as \lstinline{cmap} and \lstinline{imap} respectively.

\subsection{Scanning and parsing}

For scanning, parsing and pretty-printing we use parser- and printer-combinator
library called Ostap\footnote{http://caml.inria.fr/cgi-bin/hump.en.cgi?contrib=513}. 




\begin{lstlisting}

\end{lstlisting}

Besides parser-combinators Ostap contains a set of pretty-printer combinators, which 

\subsection{Name analysis}

The name analysis in our implementation in fact performs the following tasks:

\begin{itemize}
\item \emph{Kind analysis} --- the verification of proper usage of each name for each context this
name appears in. For example, the left side of an assignment should designate variable or procedure argument,
all references in a constant expression should designate constants etc.
\item \emph{Constant evaluation} --- the replacement of each constant expression with
its value;
\item \emph{Proper name analysis} --- establishing the relation between the usage of
named entity and its declaration;
\item \emph{Name disambiguation} --- assigning to each named entity in the program a unique
name preserving its declaration-usages coherence.
\end{itemize}

From the technical point of view the functionality of name analysis is again implemented as a 
one-pass monadic transformer with the exception monad \lstinline{Checked} and a mutable symbol 
table. This transformer actually propagates the results of reference analysis through the 
entire AST. For example, for extended statements of L2 the transformer itself looks like
the following:

\begin{lstlisting}[language=ocaml]
let resolve ref cexpr expr ext stmt =
  cmap ext 
       (mapT (fun _ s -> Monad.Checked.return s)) 
       ref 
       cexpr 
       expr 
       stmt
\end{lstlisting}

Note that we encode various contexts parametrically: here ``\lstinline{ref}'' corresponds
to the reference checking function, ``\lstinline{cexpr}'' --- to the constant expression 
checking function, ``\lstinline{expr}'' --- to the gerenic expression checking function
so actually we perform kind analysis by discriminating the cases already encoded in
the AST data structure in a type-parametric manner. 

Each expression checking function is itself aquired by applying the type-driven transformer 
for expressions to reference-checking routine of certain kind. For example, expression 
name analysis for L1 is encoded in the following manner:

\begin{lstlisting}[language=ocaml]
let reference env ext = 
  function
  | `Ident name -> 
       env#lookup name >= 
       (function x -> `Ident (env#extractInternal x, x))
  | x -> ext x

let expression env expr = 
  SimpleExpression.resolve (reference env) expr 
\end{lstlisting}

Here ``\lstinline{ext}'' is an extension for name-analysis function for references. This 
extension is provided later in the extended languges to handle the references of other kinds.

Name analysis converts the initially parsed AST into the structure of incompatible 
type. From one hand this approach enforces the safety of the compiler since, for example, an attempt
to typecheck unresolved program will not pass the typechecker; on the other hand this
safety has its' cost --- for example, a separate pretty-printer is required for a
name-resolved tree. 

\subsection{Type checking}

The type checking in our implementation follows the common scheme: we map the name-resolved
AST of the program into its type-annotated counterpart. This transformation is
actually superfluous for Oberon-0 since we do not need type information neither for
source-to-source transformation nor for the C generation; yet we still implemented it in
a generic form just to demonstrate the approach.

The most work in the type-checking phase is done at the expression level. Since the 
initial AST does not have any type information (and even does not have any ``placeholders'' 
for it) we map each expression into an isomorphic structure by \emph{pairing} each node 
with the corresponding type. Note that this transformation does not preserve the type of
the expression tree; it can not even be expressed by some parameterization of the
expression tree type. For simplicity consider the expressions made of binary operations,
constants and identifiers; then the type-pairing transformation would have the type

\begin{lstlisting}[language=ocaml]
([< `Binop of 'a * 'a | `Const of 'b | `Ident of 'c ] as 'a) ->
([> `Binop of 'd * 'd | `Const of 'b | `Ident of 'c ] * typ as 'd)
\end{lstlisting}

where \lstinline{typ} stands for the type-representing type; in the actual implementation
we should also take care of the extensibility of the type-checkers. All type-pairing
transformations are performed using type-driven transformers.

Besides annotating the expression trees with the type information the type-checking 
phase also performs the checking itself; due to the simplicity of the type system
this checking consists of merely comparisons between expected and actual types of expressions
in a various syntactic contexts.


\subsection{Source-to-source transformation}

All source-to-source transformations are actually performed on the name-resolved AST; then
the modified AST is pretty-printed. These transformations maintain all the invariants of
the name-resolved AST so it subsequently can be typechecked or undergo further 
transformations. Note that this approach simplifies the implementation a lot since all name 
disambiguation is performed on the name resolution stage.

Since sometimes we need a new names to be generated (for example for capturing the upper bounds of
FOR statements during lowering) we also provide the name generation helper which is constructed
on the name resolution stage and then is passed to the transformation functions as a parameter.

In the following subsections we consider the individual transformations.

\subsubsection{Lowering}

Lowering projects extended statements of L2 (FOR- and CASE- statements) into the composition
of simple statements of L1. This transformation is implemented using monadic transformation
using list monad since generally we transform a single statement (say, FOR) into the list
of statements. The skeleton code for the transformation is as follows:

\begin{lstlisting}[language=ocaml]
let lower ext stmt =
  let module M = SimpleStatement.Mapper (Monad.List) in 
  let module E = ExtendedStatement.Mapper (Monad.List) in
  M.gmap 
    (fun self stmt ->
       E.gmap (ext self)
              (object
                 method case _ e b s = ...
                 method forc _ i l u s b = ...
               end
              ) 
              Monad.List.return 
              Monad.List.return 
              Monad.List.return 
              stmt
    )
    (SimpleStatement.mapT (fun _ s -> [s])) 
    Monad.List.return 
    Monad.List.return
    stmt
\end{lstlisting}

Here ``\lstinline{ext}'', as usually, stands for the extension transformation. This skeleton
code just propagates the lowering transformation through all the constructs of the AST. All
nontrivial work is done by methods ``\lstinline{case}'' and 
``\lstinline{forc}''\footnote{``\lstinline{for}'' is a reserved word in OCaml.} which are 
called when the corresponding construct is encountered in the tree.

Method ``\lstinline{case}'' takes the original AST node for the CASE statement 
(which actually never used for the lowering, hence the wildcard symbol ``\lstinline{_}'' 
as a parameter placeholder), and its immediate subtrees --- key expression ``\lstinline{e}'',
list of conditional branches ``\lstinline{b}'' and the else branch ``\lstinline{s}'' --- and transforms it 
into the compound \mbox{IF-THEN-ELSIF-...-END} statement with the key value captured into the fresh variable.
Method ``\lstinline{forc}'' operates in a similar manner.

During lowering we sometimes need to construct a new fragments of AST; we facilitate this task
with the help of \emph{quotations}. A quotation is just a parser which converts a parameterized 
string into a fragment of AST. For our needs the following definition of quotation parsers turned out 
to be sufficient:

\begin{lstlisting}[language=ocaml]
let ostap (
  qexpr[qc]: "$" i:ident {qc i};
  expr [qc]: !(SimpleExpression.parse)[qexpr qc];
  stmt [qc]: !(SimpleStatement.parse)[expr qc][expr qc][stmt qc];
  stmts[qc]: oseq[stmt qc] -EOF
)
\end{lstlisting}

In short, our quotations parse arbitrary simple expressions and statements with the special form of
references --- identifiers preceded by the symbol ``\$''. Each identifier is substituted with a
some subtree during the parsing process. The substitution function ``\lstinline{qc}'' --- 
\emph{quotation context} --- is provided as a parameter for the parser. 

With the help of quotations the transformation implementation becomes more concise --- for example, 
we can use the expression

\begin{lstlisting}[language=ocaml]
   qe ["k", k; "l", l; "u", u] "($k >= $l) & ($k <= $u)"
\end{lstlisting}

for checking if the value of CASE key expression ``\lstinline{k}'' fits in the range with boundaries
``\lstinline{l}'' and ``\lstinline{u}'' of a certain case branch instead of tedious encoding of corresponding 
AST with its node constructors. Here ``\lstinline{qe}'' is just a wrapper for the parser ``\lstinline{expr}''
defined in the former code snippet which additionally takes a quotation context represented by an associative 
list.

Note that the quotation functionality is implemented in a completely independent manner to the ``main'' parsers ---
none of them are aware of quotation definitions which are kept completely local to the lowering function. Note also
that quotation parsing provides already name-resolved AST since all quotation arguments are substituted with 
the name-resolved subtrees.

\subsubsection{Type lifting}

Type lifting moves type definitions enclosed in procedures to the top level. These definitions can not be
kept inside the procedures since after procedure lifting some references to them might run out
of scope. This transformation is handcoded; nothing interesting is done here since all type names are 
already disambiguated.

\subsubsection{Procedure lifting}

Procedure lifting in our implementation comprises two transformations:

\begin{itemize}
\item \emph{Elementary procedure lifting} which moves nested procedures to the top level. This transformation, 
preceded by the type lifting, is performed prior to C generation for the language L4. Similarly to the type 
lifting, this is just a primitive transformation which is handcoded.

\item \emph{Lambda-lifting} which promotes (some) local variables and parameters of a procedure into the
argument lists of its nested subprocedures with corresponding call statements modifications. Note that in
our implementation lamba lifting \emph{does not move} procedure declarations to the top level.
\end{itemize}

While elementary lifting is used to project L4 into itself prior to C generation the lambda lifting
projects L5 into the some language which is actually a superset of L4 (since even after the lambda-lifting 
the program can still violate some L4 visibility rules for procedure declarations). 

Our lambda-lifting implementation is decomposed into the following passes:

\begin{itemize}
\item \emph{Inspection}. During this stage we traverse the AST of the program and for each procedure collect the 
names of all called procedures and all used non-local variables. The most of the 
traversal is performed using type-driven transformers with identity monad; the gathered information is 
collected in a mutable data structures. 

\item \emph{Propagation}. On this stage we propagate the collected non-local usage information through the call
graph represented by the mapping between the caller and callees. This pass is handcoded.

\item \emph{Modification}. During this stage the program is rewritten into the lambda-lifted form using the information
provided by the previous two stages. This rewriting involves changing the declaration of procedures and
their call sites, replacing usages of non-local variables into usages of procedure arguments, passed by 
reference, and introducing the type synonyms for the types of those local variables whose usages in 
nested procedures resulted in passing them as parameters. Most of the work is again performed by
type-driven transformers with identity monad.
\end{itemize}

Note that we again heavily utilize the name disambiguation performed on the name resolution stage --- we do
not need neither new names for the lifted procedure arguments nor the correspondence between newly introduced
formal and actual parameters since we can simply use the same name for the formal and actual parameter.

Despite the fact that application of type-driven monadic transformers simplified the implementation a lot the
lambda-lifting is still the most cumbersome and hard-to-understand part of our compiler.

As an observable result consider the following L5 program:

\begin{lstlisting}[language=oberon0]
MODULE L;
  PROCEDURE T;
    VAR i : INTEGER; a : ARRAY 10 OF INTEGER;
    PROCEDURE Init;
    BEGIN
      FOR i:=1 TO 10 DO a[i] := i END
    END Init;
  BEGIN
    Init ()  
  END T;
BEGIN
  T ()
END L.
\end{lstlisting}

The source-to-source transformation is performed in the following order:

\begin{itemize}
\item Type lifting;
\item Lambda-lifting;
\item Procedure lifting;
\item Lowering.
\end{itemize}

As a result the following L4-code in produced:

\begin{lstlisting}[language=oberon0]
MODULE L;
  TYPE
    typename = ARRAY 10 OF INTEGER;
  PROCEDURE global_top_T_Init 
  (VAR global_top_T_a : typename; 
   VAR global_top_T_i : INTEGER);
  VAR
    upb : INTEGER;
  BEGIN
    global_top_T_i := 1; 
    upb := 10; 
    WHILE (1 > 0) & (global_top_T_i <= upb) OR 
          (1 <= 0) & (global_top_T_i >= upb)
      DO
        global_top_T_a[global_top_T_i] := global_top_T_i; 
        global_top_T_i := global_top_T_i + 1
      END
  END global_top_T_Init;
  PROCEDURE global_top_T ();
  VAR
    global_top_T_i : INTEGER;
    global_top_T_a : typename;
  BEGIN
    global_top_T_Init (global_top_T_a, global_top_T_i)
  END global_top_T;
  BEGIN
    global_top_T ()
END L.
\end{lstlisting}

\subsection{Code generation}

There is no dedicated code generation pass in our implementation --- we consider C representation
as an alternative concrete syntax for the name-resolved (and lifted) AST. Pretty-printers for the relevant
structures (simple expressions with L4 references, simple statements with procedure calls, 
type-, variable- and procedure declarations) are implemented in a generic form: they take a
\emph{printing scheme} which encapsulates the concrete syntax elements as an additional
parameter. Note that we need a name-resolved tree to distinguish, for example, referenced-passed
function parameters from value-passed ones in both function argument declaration list, all
their usages within the function body and actual parameters of function invocation.

\subsection{Artifacts}

\subsection{Observations}

\subsection{Conclusions}
